# URL Aggregator

В этом задании вам предстоит написать функцию, которая будет проходиться GET запросами по переданным URL адресам и
агрегировать результаты выполнения этих запросов. Задание фокусируется на асинхронном программировании, работе с
горутинами, каналами и обеспечении потокобезопасности.

## Задачи

### 1. Реализовать тип результата агрегации

Чтобы получать информацию о промежуточных результатах функции параллельно, во время ее выполнения, нам понадобится свой
тип результата агрегации:

- Контракт на тип определяется интерфейсом `AggregationResult` в [contract.go](./contract.go)
- Вы описываете свою имплементацию (структуру) в [result.go](./result.go)
- Вы можете (а в данном случае скорее должны) добавить к имплементации свои дополнительные методы, не описанные в
  интерфейсе, необходимые для корректной работы с типом.
- Тип должен корректно инкапсулировать логику, т.е. защищать от изменений со стороны потребителей, пользующихся им через
  интерфейс `AggregationResult`, или из других пакетов

**Требования к реализации:**

- Потокобезопасность: методы можно вызывать concurrently из разных горутин
- Актуальные данные: методы должны возвращать актуальные данные по мере поступления результатов запросов
- Корректная работа с `Done()`: метод должен правильно отражать состояние завершения агрегации

### 2. Реализовать метод Aggregate

Вам нужно реализовать метод `Aggregate` типа `ResponseCodeAggregator` в [aggregator.go](./aggregator.go):

**Основные требования:**

- Агрегация должна быть асинхронной: по горутине на каждый URL или пул воркеров, на ваш выбор
- Метод должен вернуть `AggregationResult` _немедленно_, т.е. не дожидаясь завершения всех HTTP-запросов
- Сигнатура метода зафиксирована, менять можно только код внутри

**Обработка отмен и ожиданий:**

- Метод принимает канал url'ов в аргументах, вам гарантировано, что этот канал когда-то будет закрыт
- Метод должен корректно обрабатывать отмену контекста:
    - Прекращать обработку новых url'ов
    - Если контекст отменился в процессе ожидания ответа от определенного url'а, то прерваться не дожидаясь ответа

**HTTP запросы:**

- Метод должен посылать запросы через `HttpClient.Get`, он возвращает `http.Response`: обратите внимание
  в [документации](https://pkg.go.dev/net/http) как правильно с ним работать
- В случае если запрос завершается с ошибкой (именно ошибкой вызова метода, `err != nil`), логгируем ошибку в
  произвольном формате

**Качество кода:**

- Не должно быть утечек памяти, утечек горутин, или race condition'ов
- Используйте правильные паттерны для работы с горутинами и каналами

Примеры работы с `ResponseCodeAggregator` описаны в [aggregator_example_test.go](./aggregator_example_test.go).

### 3. Ответить на вопросы по заданию

В файле [questions.md](./questions.md) напиши ответы на вопросы, связанные с заданием.

## Запуск

### Компиляция

Из корня репозитория

```bash
go install -race ./homeworks/hw1/urls/
```

Флаг `-race` позволяет отслеживать data race'ы

### Запуск тестов

```bash
go test -race -v ./homeworks/hw1/urls/
```

## Полезные ссылки:

- Работа с HTTP: https://pkg.go.dev/net/http
- Особенности асинхронной работы с map в Go: https://go.dev/blog/maps#concurrency
- Стандартный логгер: https://pkg.go.dev/log
- (Альтернативно) Структурированный логгер: https://pkg.go.dev/log/slog
- Для вдохновения на реализацию асинхронной логики: https://go.dev/blog/pipelines
- Как искать race conditions: https://go.dev/doc/articles/race_detector
